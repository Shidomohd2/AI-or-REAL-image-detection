{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zCJ9ElPGxGD4n6_OOvk9BuRI8m1MOW3C",
      "authorship_tag": "ABX9TyMmpMP2gKf/gFXgzIDuplm6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgYrtDJYXIzi"
      },
      "outputs": [],
      "source": [
        "# Install Required Libraries\n",
        "!pip install --upgrade kagglehub tensorflow scikit-learn tqdm\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # Progress tracking\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "import gc  # Garbage Collection\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Enable Mixed Precision for Faster Training\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Control GPU Memory Growth (85% Limit)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_virtual_device_configuration(\n",
        "                gpu,\n",
        "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=int(0.85 * 15360))]  # 85% of 15 GB\n",
        "            )\n",
        "        print(\" GPU Memory Growth Limited to 85%\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Download dataset from Kaggle\n",
        "dataset_path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
        "print(\"Dataset downloaded to:\", dataset_path)\n",
        "\n",
        "#  Define dataset directories\n",
        "train_dir = os.path.join(dataset_path, \"train\")\n",
        "test_dir = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "#  Fix Image Size (MobileNetV2 uses 224x224)\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "#  Data Generators\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir, target_size=img_size, batch_size=batch_size, class_mode='binary', shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir, target_size=img_size, batch_size=batch_size, class_mode='binary', shuffle=False\n",
        ")\n",
        "\n",
        "#  Load MobileNetV2 for Feature Extraction (Efficient and Lightweight)\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze model\n",
        "\n",
        "#   Function to Extract Features Efficiently with GPU\n",
        "def extract_features_in_batches(generator, dataset_name=\"Dataset\"):\n",
        "    features = []\n",
        "    labels = []\n",
        "    total_batches = len(generator)\n",
        "    print(f\"\\n   Extracting Features for {dataset_name}...\")\n",
        "\n",
        "    for _ in tqdm(range(total_batches), desc=f\"   {dataset_name} Batches\"):\n",
        "        # Get a batch of images and labels\n",
        "        x_batch, y_batch = next(generator)\n",
        "\n",
        "        # Convert batch to TensorFlow Dataset for optimized GPU processing\n",
        "        x_batch = tf.convert_to_tensor(x_batch)\n",
        "\n",
        "        # Extract features using MobileNetV2\n",
        "        batch_features = base_model(x_batch, training=False)\n",
        "        batch_features = tf.keras.layers.GlobalAveragePooling2D()(batch_features)\n",
        "        batch_features = batch_features.numpy()  # Convert to NumPy\n",
        "\n",
        "        # Store features and labels\n",
        "        features.append(batch_features)\n",
        "        labels.extend(y_batch)\n",
        "\n",
        "        # Clear Memory\n",
        "        del x_batch, y_batch, batch_features\n",
        "        gc.collect()\n",
        "\n",
        "    # Combine all batches\n",
        "    features = np.vstack(features)\n",
        "    labels = np.array(labels)\n",
        "    return features, labels\n",
        "\n",
        "#   Extract Features for Training and Testing\n",
        "train_features, train_labels = extract_features_in_batches(train_generator, dataset_name=\"Training\")\n",
        "test_features, test_labels = extract_features_in_batches(test_generator, dataset_name=\"Testing\")\n",
        "\n",
        "#   Train Random Forest Classifier\n",
        "print(\"\\n   Training Random Forest Classifier...\")\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(train_features, train_labels)\n",
        "print(\"  Training Completed\")\n",
        "\n",
        "#   Make Predictions\n",
        "predictions = clf.predict(test_features)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(test_labels, predictions))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(test_labels, predictions))\n",
        "\n",
        "#   Save the Model\n",
        "joblib.dump(clf, \"cifake_rf_model.pkl\")\n",
        "print(\"\\n  Random Forest Model saved as cifake_rf_model.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow joblib numpy pillow\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import gc  # Garbage collection\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "#   Load the trained model correctly\n",
        "model_path = \"cifake_rf_model.pkl\"\n",
        "\n",
        "# Ensure model file exists before loading\n",
        "if os.path.exists(model_path):\n",
        "    with open(model_path, \"rb\") as f:\n",
        "        model = joblib.load(f)\n",
        "    print(\"  Model loaded successfully!\")\n",
        "else:\n",
        "    print(\"    Model file not found! Retrain the model or upload 'cifake_rf_model.pkl'.\")\n",
        "\n",
        "#   Load MobileNetV2 for Feature Extraction\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze model layers\n",
        "\n",
        "#   Function to Extract Features from Image\n",
        "def extract_features(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))  # Resize image\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = preprocess_input(img_array)  # Preprocess for MobileNetV2\n",
        "\n",
        "    features = base_model(img_array, training=False)  # Extract Features\n",
        "    features = tf.keras.layers.GlobalAveragePooling2D()(features)  # Pooling\n",
        "    return features.numpy()\n",
        "\n",
        "#   Upload Image in Google Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    # Get the first uploaded file\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    print(f\"\\n  Uploaded File: {filename}\")\n",
        "\n",
        "    # Extract Features & Predict\n",
        "    features = extract_features(filename)\n",
        "    prediction = model.predict(features.reshape(1, -1))[0]\n",
        "    result = \"AI-generated\" if prediction == 0 else \"Real world image\"\n",
        "\n",
        "    #   Show Image & Prediction Result\n",
        "    img = image.load_img(filename)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Prediction: {result}\", fontsize=16, fontweight=\"bold\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n **Prediction Result:** {result}\")\n",
        "\n",
        "#   Clear Memory\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "k_0xlKLwPX4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}